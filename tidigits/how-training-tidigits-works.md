---
layout: default
title: How To Train TIDIGITS
---

#Introduction
TIDigits is a comparatively simple connected digits recognition task.
Like many well-known corpia, Kaldi includes a example script for it.
It is fairly typical for the example scripts.

The example script can be foung in `kaldi-trunk/egs/tidigits/s5/` all other scripts refered to here are relitive to that path. Kaldi example scripts are all written to be run from that path (or it equivelent in other examples) even if they are located in a subfolder.
Kaldi example scripts should only be run in `bash`

The offical [Kaldi tuitorial](http://kaldi.sourceforge.net/tutorial.html) is a bit all over the place, but worth a look, it is no doubt getting better as the software matures.

##The Three Major Steps

There are Three Steps to applying Kaldi to a task such as this.

<ol>
<li> Data Preparation:
<ul>
   <li> Locating the datafiles</li>
   <li> Parsing its annotations (eg Speaker Labels, Utterance Labels)</li>
   <li> Converting the audio data format</li>
</ul></li>
<li> Language Preparation:
<ul>
   <li> Creating a Language Model in OpenFST</li>
</ul></li>
<li>Training/Evaluating the Speach Recogniser:
<ul>
<li> This is the only step that is actually done in Kali proper, rather than by helper scripts and tools.</li>
<li> Viewing the results is also nontrivial</li>
<li> Kaldi does not store results in the most clear way,</li>
</ul></li
</ol>

The full process can be carried out by running `bash run.sh`. Though you most likly need to edit at least the TIDIGITs path, and the `cmd.sh` (so that it is set to run locally, not on a cluster).


#Data Preparation
[The offical kaldi documentation on this section](http://kaldi.sourceforge.net/data_prep.html#data_prep_data). It is the basis of alot of this section.

These steps are carried out by the script `local/tidigits_data_prep.sh`. It takes one parameter -- the path to the dataset.

One should realise after looking at this section (and the next), just how valuable AWK and Bash (or equivelents) are for this task.


##Locate the Dataset 
on on the SIP network, the TIDIGITs data set can be found at `/user/data14/res/speech_data/tidigits/`. Symlink it into a convient location.

##Parse its anonotations
Files such as `wav.scp` need to be generated for 

###Kaldi Script: `.scp`: Basically just a list of Utterances to Filenames
A Kaldi script file is just a mapping from record_id, to extended-filenames.

Line Format:

```
<recording_id> <extended_filename>
```

####Recording ID
The recording ID is the first part of each line in a  `.scp` file.
If speaker id is available (which is is for tidigits), it should form the first part of the recording id.
Kaldi requires this not for speaker identification, but for purposes of sorting for training (`utt2spk` is for that).

The remained of the speaker ID is arbairy, so long as it is unique.
For convience of generating the unique id, the example script for TIDIGITS uses
`<speaker-id>_<transcription><sessionid>`.

As there is only one Utterance per recording in TIDIGITS, the Recording ID is the Utterannce ID.
(See below)


####Extended Filename
The second part of the line is the extended filename
Extended Filename is the term used by Kaldi,  to refer ot a string that is either the path to a wav-format file or it is a bash command that will output wav-format data to standard out, followed by a pipe symbol (`|`).

As the TIDIGITS data is in the [SPHERE audio format](http://www.ee.columbia.edu/ln/LabROSA/doc/HTKBook21/node64.html), it needs to be converted to wav.
So the sample scripts in Kaldi use `sph2pipe` to convert them, so the .scp files lines will look like: (assuming `sph2pipe` is on your PATH, otherwise Path to the executable will need to be used)

```
ad_16a sph2pipe -f wav ../tidigits/test/girl/ad/16a.wav |
```

###Segmentation File `segments`
If there were multiple utterances per recording then there would need to be a segementation file as well,
mapping RecordingIDs and Start-End times to Utterance IDs.
(See [The offical kaldi documentation on this section](http://kaldi.sourceforge.net/data_prep.html#data_prep_data)).
As there is not, by not creating a `segments` file, Kaldi defaults to utterance id == recording id.


###Text Transcription file `text`
The text transcription must be stored in a file, which the example calls `text`.
each line is an utterance-id followed by a transcription of what is said. 
Eg:

```
ad_1oa 1 o
ad_1z1za 1 z 1 z
ad_1z6a 1 z 6
ad_23461a 2 3 4 6 1
```

Notice the Utterance-ID format as descibed above.
Notice also, for later, that the transcription here is in word space, not phoneme space.

###Utterance to Speaker Mappings `utt2spk`
This file maps each utterance id to a speaker id.
Each line has the form `<utterance id> <speaker-id>`.

`spk2utt` is the opposite, and can be generated by using the script `utils/utt2spk_to_spk2utt.pl`.
Each like starts with a speaker id, then has every utterance id they spoke.

#Language Preparation
[The offical kaldi documentation on this section](http://kaldi.sourceforge.net/data_prep.html#data_prep_lang).

To understand this section you should first [understand openFST]( ../fst-example/intro_to_OpenFST.md).

## The Lexicon File.
The example recipy for TIDIGITs is quiet clever about contructing the phoneneme to word FST.
There script `util/make_lexicon_fst.pl` takes a lexicon file, and outputs a text FST file.
Each line of the Lexicon file has the format:

```
<word> <phoneme> <phoneme> <phonen....
```

ie one word followed by its phonene make up, specified with space delimited symbols.

The Full break-down of how to use it:

Usage: make_lexicon_fst.pl [--pron-probs] lexicon.txt [silprob silphone [sil_disambig_sym]] >lexiconfst.txt
Creates a lexicon FST that transduces phones to words, and may allow optional silence.
Note: ordinarily, each line of lexicon.txt is: word phone1 phone2 ... phoneN; if the --pron-probs option is
used, each line is: word pronunciation-probability phone1 phone2 ... phoneN.  The probability 'prob' will
typically be between zero and one, and note that it's generally helpful to normalize so the largest one
for each word is 1.0, but this is your responsibility.  The silence disambiguation symbol, e.g. something
like #5, is used only when creating a lexicon with disambiguation symbols, e.g. L_disambig.fst, and was
introduced to fix a particular case of non-determinism of decoding graphs.

#Training/Evaluating Recogniser

